"""
The Orchestrator — Master / Workers (Production)
=================================================
Global Scanner (real Polymarket + OpenAI GPT-4o) → Execution Engine (multi-user).
IA results cached in Redis for 5 min to avoid paying per-user.
"""

from __future__ import annotations

import asyncio
import hashlib
import json
import os
import time
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Any, Optional

import httpx
import structlog

from api.websocket_manager import engine_logs_manager
from db.credentials import get_polymarket_credentials_decrypted
from db.models import BotInstance, BotStatus, TradeLog, init_db
from db.session import get_session

logger = structlog.get_logger()

_scanner_task: Optional[asyncio.Task] = None
_openai_paused_until: float = 0.0  # Unix timestamp for rate-limit pause

GAMMA_API_URL = "https://gamma-api.polymarket.com/markets"
OPENAI_CHAT_URL = "https://api.openai.com/v1/chat/completions"

# In-memory fallback cache when Redis is not available
_memory_cache: dict[str, tuple[float, str]] = {}
CACHE_TTL_S = 300  # 5 minutes


# =============================================================================
# Redis helpers (graceful fallback to in-memory)
# =============================================================================

_redis_client: Any = None


def _get_redis() -> Any:
    """Lazy-init Redis. Returns None if unavailable."""
    global _redis_client
    if _redis_client is not None:
        return _redis_client
    redis_url = os.environ.get("REDIS_URL", "").strip()
    if not redis_url:
        return None
    try:
        import redis as redis_lib
        _redis_client = redis_lib.Redis.from_url(redis_url, decode_responses=True, socket_timeout=2)
        _redis_client.ping()
        logger.info("Redis connected for IA cache")
        return _redis_client
    except Exception as e:
        logger.warning("Redis unavailable, using in-memory cache", error=str(e))
        _redis_client = None
        return None


def _cache_get(key: str) -> Optional[str]:
    r = _get_redis()
    if r:
        try:
            return r.get(key)
        except Exception:
            pass
    entry = _memory_cache.get(key)
    if entry and time.time() - entry[0] < CACHE_TTL_S:
        return entry[1]
    return None


def _cache_set(key: str, value: str) -> None:
    r = _get_redis()
    if r:
        try:
            r.setex(key, CACHE_TTL_S, value)
            return
        except Exception:
            pass
    _memory_cache[key] = (time.time(), value)


# =============================================================================
# TradeSignal
# =============================================================================


@dataclass
class TradeSignal:
    """Signal generated by GPT-4o after market analysis."""

    market_id: str
    market_question: str
    ia_probability: float
    confidence: float
    recommended_side: str  # YES | NO
    market_price: float
    edge_pct: float
    reasoning: str = ""


# =============================================================================
# Global Scanner — Polymarket Fetch (real)
# =============================================================================


async def _fetch_polymarket_markets(limit: int = 5) -> list[dict[str, Any]]:
    """Fetch top markets by 24h volume from Polymarket Gamma API."""
    try:
        async with httpx.AsyncClient(timeout=15.0) as client:
            resp = await client.get(
                GAMMA_API_URL,
                params={
                    "limit": limit,
                    "order": "volume24hr",
                    "ascending": "false",
                    "closed": "false",
                    "active": "true",
                },
            )
            resp.raise_for_status()
            data = resp.json()
    except Exception as e:
        logger.error("Polymarket fetch failed", error=str(e))
        return []

    markets: list[dict[str, Any]] = []
    for m in data:
        try:
            raw_prices = m.get("outcomePrices", "[]")
            if isinstance(raw_prices, str):
                prices = json.loads(raw_prices)
            else:
                prices = raw_prices or []
            yes_price = float(prices[0]) if len(prices) >= 1 else 0.5
            no_price = float(prices[1]) if len(prices) >= 2 else 1.0 - yes_price

            markets.append({
                "market_id": m.get("conditionId", m.get("id", "")),
                "question": m.get("question", ""),
                "description": (m.get("description", "") or "")[:500],
                "yes_price": yes_price,
                "no_price": no_price,
                "volume24hr": float(m.get("volume24hr", 0) or 0),
                "liquidity": float(m.get("liquidityNum", m.get("liquidity", 0)) or 0),
            })
        except (json.JSONDecodeError, ValueError, TypeError):
            continue

    logger.info("Polymarket markets fetched", count=len(markets))
    return markets


# =============================================================================
# OpenAI GPT-4o Analysis (with Redis cache + rate-limit pause)
# =============================================================================

SYSTEM_PROMPT = """You are an expert prediction market analyst. You evaluate whether the current market price is undervalued or overvalued based on your knowledge of world events, geopolitics, economics, and probability theory.

You MUST respond with ONLY valid JSON — no markdown, no explanation outside the JSON:
{"probability": float between 0 and 1, "confidence": float between 0 and 1, "reasoning": "one paragraph explanation"}

"probability" = your estimated true probability that this event resolves YES.
"confidence" = how confident you are in your estimate (0.3 = low, 0.7 = high, 0.9 = very high).
"""


async def _analyze_with_openai(market: dict[str, Any]) -> Optional[TradeSignal]:
    """
    Call GPT-4o to analyze a single market.
    Uses Redis cache (5min TTL) to avoid duplicate API calls.
    """
    global _openai_paused_until

    # Rate-limit pause
    if time.time() < _openai_paused_until:
        remaining = int(_openai_paused_until - time.time())
        logger.info("OpenAI paused (rate limit)", remaining_s=remaining)
        return None

    api_key = os.environ.get("OPENAI_API_KEY", "").strip()
    if not api_key:
        logger.warning("OPENAI_API_KEY not set — falling back to mock analysis")
        return await _mock_ia_analyze(market)

    market_id = market.get("market_id", "unknown")
    question = market.get("question", "")
    yes_price = float(market.get("yes_price", 0.5))
    description = market.get("description", "")

    # Check cache
    cache_key = f"be:ia:{hashlib.md5(market_id.encode()).hexdigest()}"
    cached = _cache_get(cache_key)
    if cached:
        logger.debug("IA cache hit", market_id=market_id[:12])
        try:
            result = json.loads(cached)
            return _build_signal(market_id, question, yes_price, result)
        except Exception:
            pass

    # Build prompt
    user_prompt = (
        f"Market: {question}\n"
        f"Description: {description[:300]}\n"
        f"Current YES price: {yes_price:.3f} (implies {yes_price*100:.1f}% probability)\n"
        f"Current NO price: {1-yes_price:.3f}\n"
        f"24h Volume: ${market.get('volume24hr', 0):,.0f}\n\n"
        f"Is the current price undervalued or overvalued? Respond in JSON only."
    )

    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            resp = await client.post(
                OPENAI_CHAT_URL,
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": "gpt-4o",
                    "messages": [
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user", "content": user_prompt},
                    ],
                    "temperature": 0.2,
                    "max_tokens": 300,
                },
            )

        if resp.status_code == 429:
            _openai_paused_until = time.time() + 60
            logger.warning("OpenAI rate limited — pausing 60s")
            return None

        resp.raise_for_status()
        data = resp.json()
        content = data["choices"][0]["message"]["content"].strip()

        # Parse JSON from response (strip markdown fences if present)
        if content.startswith("```"):
            content = content.split("\n", 1)[-1].rsplit("```", 1)[0].strip()
        result = json.loads(content)

        # Cache for 5 minutes
        _cache_set(cache_key, json.dumps(result))

        logger.info(
            "OpenAI analysis complete",
            market_id=market_id[:12],
            ia_prob=result.get("probability"),
            confidence=result.get("confidence"),
        )

        return _build_signal(market_id, question, yes_price, result)

    except json.JSONDecodeError as e:
        logger.warning("OpenAI returned non-JSON", error=str(e), market_id=market_id[:12])
        return None
    except httpx.HTTPStatusError as e:
        if e.response.status_code == 429:
            _openai_paused_until = time.time() + 60
            logger.warning("OpenAI rate limited — pausing 60s")
        else:
            logger.error("OpenAI API error", status=e.response.status_code, error=str(e))
        return None
    except Exception as e:
        logger.error("OpenAI call failed", error=str(e))
        return None


def _build_signal(market_id: str, question: str, yes_price: float, result: dict) -> Optional[TradeSignal]:
    """Build TradeSignal from parsed OpenAI JSON."""
    try:
        ia_prob = float(result["probability"])
        confidence = float(result.get("confidence", 0.5))
        reasoning = result.get("reasoning", "")
    except (KeyError, ValueError, TypeError):
        return None

    ia_prob = max(0.01, min(0.99, ia_prob))
    confidence = max(0.0, min(1.0, confidence))

    side = "YES" if ia_prob > yes_price else "NO"
    edge = abs(ia_prob - yes_price) * 100

    if edge < 5 or confidence < 0.4:
        return None

    return TradeSignal(
        market_id=market_id,
        market_question=question,
        ia_probability=ia_prob,
        confidence=confidence,
        recommended_side=side,
        market_price=yes_price,
        edge_pct=round(edge, 1),
        reasoning=reasoning[:200],
    )


# =============================================================================
# Mock fallback (when OPENAI_API_KEY not set)
# =============================================================================


async def _mock_ia_analyze(market: dict) -> Optional[TradeSignal]:
    """Fallback mock analysis when no OpenAI key."""
    import random

    await asyncio.sleep(0.3)
    market_id = market.get("market_id", "unknown")
    question = market.get("question", "")
    yes_price = float(market.get("yes_price", 0.5))

    ia_prob = round(0.3 + random.random() * 0.4, 2)
    side = "YES" if ia_prob > yes_price else "NO"
    edge = abs(ia_prob - yes_price) * 100
    if edge < 5:
        return None

    return TradeSignal(
        market_id=market_id,
        market_question=question,
        ia_probability=ia_prob,
        confidence=0.5,
        recommended_side=side,
        market_price=yes_price,
        edge_pct=round(edge, 1),
        reasoning="Mock analysis — OPENAI_API_KEY not set",
    )


# =============================================================================
# Global Scanner Loop (Master)
# =============================================================================


async def global_scanner_loop() -> None:
    """
    Master loop: fetch markets → OpenAI analysis → dispatch to workers.
    Runs every 60s. One signal per cycle.
    """
    logger.info("Global Scanner started")

    while True:
        try:
            markets = await _fetch_polymarket_markets(limit=5)
            if not markets:
                await asyncio.sleep(60)
                continue

            for market in markets:
                signal = await _analyze_with_openai(market)
                if signal:
                    logger.info(
                        "Edge detected",
                        market_id=signal.market_id[:12],
                        edge=signal.edge_pct,
                        side=signal.recommended_side,
                        confidence=signal.confidence,
                    )

                    # Broadcast to all connected users
                    for uid in _get_running_user_ids():
                        await engine_logs_manager.send_personal_message(
                            f"[SCANNER] Analyzing: {signal.market_question[:60]}... "
                            f"Edge={signal.edge_pct:.1f}% ({signal.recommended_side})",
                            uid,
                        )

                    await execution_engine(signal)
                    break  # One signal per cycle

            await asyncio.sleep(60)

        except asyncio.CancelledError:
            logger.info("Global Scanner cancelled")
            raise
        except Exception as e:
            logger.error("Global Scanner error", error=str(e))
            await asyncio.sleep(60)


def _get_running_user_ids() -> list[int]:
    """Fetch user_ids with RUNNING bots."""
    try:
        init_db()
        with get_session() as session:
            bots = session.query(BotInstance).filter(BotInstance.status == BotStatus.RUNNING).all()
            return [b.user_id for b in bots]
    except Exception:
        return []


# =============================================================================
# Execution Engine (Workers)
# =============================================================================


def _kelly_position_size(
    bankroll: float,
    ia_probability: float,
    market_price: float,
    side: str,
    kelly_fraction: float = 0.25,
) -> float:
    """Fractional Kelly Criterion. f* = (bp - q) / b. Capped at 5% of bankroll."""
    if side == "YES":
        p = ia_probability
        b = (1 - market_price) / market_price if market_price > 0 else 1
    else:
        p = 1 - ia_probability
        b = market_price / (1 - market_price) if market_price < 1 else 1

    q = 1 - p
    f = (b * p - q) / b if b > 0 else 0
    f = max(0, min(f * kelly_fraction, 0.05 * bankroll))
    return round(f, 2)


async def _send_log(user_id: int, message: str) -> None:
    """Push log to user's WebSocket terminal."""
    await engine_logs_manager.send_personal_message(message, user_id)


async def _execute_for_user(user_id: int, signal: TradeSignal) -> None:
    """
    Execute trade for one user (isolated).
    Decrypts keys, computes Kelly, executes (or dry-runs), logs to DB + WebSocket.
    """
    try:
        init_db()
        dry_run = os.environ.get("POLYMARKET_DRY_RUN", "true").lower() == "true"

        with get_session() as session:
            creds = get_polymarket_credentials_decrypted(session, user_id)
            if not creds:
                await _send_log(user_id, "[WARNING] No Polymarket credentials. Go to Settings > Setup.")
                return

            proxy_key, secret, passphrase = creds
            bankroll = 1000.0  # TODO: fetch real balance via Alchemy/CLOB
            size = _kelly_position_size(
                bankroll=bankroll,
                ia_probability=signal.ia_probability,
                market_price=signal.market_price,
                side=signal.recommended_side,
            )

            if size <= 0:
                await _send_log(user_id, "[SKIP] Kelly size = $0 — edge too small for position")
                return

            # Log the analysis
            await _send_log(
                user_id,
                f"[TRADE] Analysis complete. Edge detected ({signal.edge_pct:.1f}%). "
                f"Executing ${size:.2f} {signal.recommended_side} on: {signal.market_question[:50]}..."
            )

            if dry_run:
                await _send_log(user_id, f"[DRY RUN] Simulated ${size:.2f} {signal.recommended_side}")
                logger.info("Dry run trade", user_id=user_id, size=size, side=signal.recommended_side)
            else:
                # TODO: Real execution via py-clob-client with user's decrypted keys
                await _send_log(user_id, f"[LIVE] Executing ${size:.2f} {signal.recommended_side} via CLOB...")
                logger.info("Live trade (stub)", user_id=user_id, size=size)

            await asyncio.sleep(0.5)

            trade = TradeLog(
                user_id=user_id,
                market_id=signal.market_id,
                market_question=signal.market_question,
                side=signal.recommended_side,
                size_usd=size,
                price=signal.market_price,
                ia_probability=signal.ia_probability,
                confidence=signal.confidence,
                kelly_fraction=0.25,
                status="DRY_RUN" if dry_run else "FILLED",
                pnl=0.0,
            )
            session.add(trade)

            bot = session.query(BotInstance).filter(BotInstance.user_id == user_id).first()
            if bot:
                bot.last_heartbeat = datetime.now(timezone.utc)
                bot.last_log = (
                    f"{'[DRY]' if dry_run else '[LIVE]'} "
                    f"{signal.recommended_side} ${size:.2f} on {signal.market_question[:40]}..."
                )

            await _send_log(user_id, f"[OK] Trade logged — {signal.market_id[:12]}...")

    except Exception as e:
        logger.error("Execution failed for user", user_id=user_id, error=str(e))
        await _send_log(user_id, f"[ERROR] {str(e)[:120]}")
        try:
            with get_session() as session:
                bot = session.query(BotInstance).filter(BotInstance.user_id == user_id).first()
                if bot:
                    bot.status = BotStatus.ERROR
                    bot.last_log = f"Error: {str(e)[:80]}"
        except Exception:
            pass


async def execution_engine(signal: TradeSignal) -> None:
    """Find all RUNNING bots, execute trade for each in parallel."""
    user_ids = _get_running_user_ids()

    if not user_ids:
        logger.info("No active bots to execute")
        return

    logger.info("Execution Engine: dispatching", count=len(user_ids))

    for uid in user_ids:
        await engine_logs_manager.send_personal_message(
            f"[SCANNER] Edge detected ({signal.edge_pct:.1f}%) — dispatching to {len(user_ids)} user(s)",
            uid,
        )

    tasks = [_execute_for_user(uid, signal) for uid in user_ids]
    await asyncio.gather(*tasks)


# =============================================================================
# Lifecycle
# =============================================================================


def start_scanner() -> asyncio.Task:
    """Start the Global Scanner in background."""
    global _scanner_task
    _scanner_task = asyncio.create_task(global_scanner_loop())
    return _scanner_task


async def stop_scanner() -> None:
    """Cancel the Global Scanner task."""
    global _scanner_task
    if _scanner_task:
        _scanner_task.cancel()
        try:
            await _scanner_task
        except asyncio.CancelledError:
            pass
        _scanner_task = None
        logger.info("Global Scanner stopped")
